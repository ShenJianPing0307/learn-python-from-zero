## 一、线程调用方式

### （一）threading.Thread

```python
from threading import Thread
from os import cpu_count
import time

url_list = [
    'https://www.baidu.com',
    'https://www.zhihu.com',
    'https://www.163.com',
]

def handle_task(task):
    time.sleep(1)
    print(task, time.ctime())

if __name__ == '__main__':
    start_time = time.time()
    t_list = []
    for url in url_list:
        t = Thread(target=handle_task, args=(url,))
        t_list.append(p)
        t.start()

    for t in t_list:
        t.join() # 子进程执行结束后才能结束主进程

    end_time = time.time()
    print(end_time-start_time)
```

### （二）继承式调用

```python
from threading import Thread
import time

url_list = [
    'https://www.baidu.com',
    'https://www.zhihu.com',
    'https://www.163.com',
]


class MyThread(Thread):

    def __init__(self, url):
        self.url = url
        super(MyThread, self).__init__()  # 父类初始化变量

    def run(self):
        """
        线程必须运行的线程体
        :return:
        """
        time.sleep(1)
        print(self.url, time.ctime())


if __name__ == '__main__':
    t_list = []
    for url in url_list:
        t = MyThread(url)
        t.start()

    [t.join() for t in t_list]

```

### （三）concurrent.futures模块

#### 1、普通方式

```python
from concurrent.futures import ThreadPoolExecutor
import requests
import time


def task(url):

    response=requests.get(url)
    print(response,time.ctime())


pool=ThreadPoolExecutor(5)

url_list=[
    'https://www.baidu.com',
    'https://www.zhihu.com',
    'https://www.163.com',
]
for url in url_list:
    pool.submit(task,url) #异步提交任务

pool.shutdown() #相当于进程池的pool.close()+pool.join()操作

```

#### 2、回调函数方式

```python
from concurrent.futures import ThreadPoolExecutor
import requests
import time


def task(url):
    response = requests.get(url)
    return response


# ########d###
def done(future, *args, **kwargs):
    """
    done为回调函数，task执行的结果返回给future,将结果与之后的动作分离开来

    :param future:
    :param args:
    :param kwargs:
    :return:
    """
    response = future.result()
    print(response.text)


pool = ThreadPoolExecutor(5)

url_list = [
    'https://www.baidu.com',
    'https://www.zhihu.com',
    'https://www.163.com',
]
for url in url_list:
    res = pool.submit(task, url)
    res.add_done_callback(done)

pool.shutdown()
```

## 二、threading.local模块

```python
from threading import local, Thread, current_thread

data = local()  # 定义一个全局的local对象

print(data, type(data))


def handle():
    data.x = 1

    for i in range(50):
        data.x += 1
    print(current_thread(), data.x)


if __name__ == '__main__':

    for i in range(5):
        t = Thread(target=handle)
        t.start()

```

可以看到每一个线程输出的值都是一样的，虽然定义了全局对象local，但是定义的data.x属性是每一个线程独有的。本质是不同的线程使用同一个local对象创建不同的数据字典。

threading.local模块可以对线程的数据进行管理：

- local模块实例化全局对象
- 每一个线程在使用这个对象都将创建自己的一个字典，类似于局部变量
- 每一个线程数据字典是独立的，互不干扰，试图去读取其它线程的数据会导致错误

## 三、全局变量和局部变量

### （一）全局变量

```python
from threading import local, Thread, current_thread

data = local()  # 定义一个全局的local对象

print(data, type(data))


def handle():
    data.x = 1

    for i in range(50):
        data.x += 1
    print(current_thread(), data.x)


if __name__ == '__main__':

    for i in range(5):
        t = Thread(target=handle)
        t.start()

```

定义全局变量x，这样每一个线程都更改同一个变量，导致计算杂乱无章。

### （二）局部变量

```python
from threading import Thread, current_thread


def handle():
    x = 1
    for _ in range(50):
        x += 1
    print(current_thread(), x)


if __name__ == '__main__':
    for i in range(5):
        t = Thread(target=handle)
        t.start()

```

## 四、线程同步

### （一）threading.Lock 同步锁/互斥锁

当遇到多个线程操作同一个资源时，会引发资源安全或者错乱的情况，此时可以使用同步锁/互斥锁进行解决，在某一时刻只允许一个线程来操作该资源。比较形象的比喻就是房子外面挂着一把钥匙，谁拿着钥匙就进去，直到钥匙被归还，另一个线程再拿着钥匙进去。

```python
from threading import Thread, Lock

x = 100


def handle(lock):
    global x
    lock.acquire()  # 拿到钥匙
    x -= 1
    lock.release()  # 归还钥匙


if __name__ == '__main__':
    lock = Lock()

    t_list = []
    for i in range(5):
        t = Thread(target=handle, args=(lock,))
        t_list.append(t)
        t.start()
    [t.join() for t in t_list]

    print(x)

```

### （二）threading.RLock 递归锁

解决死锁问题，如下所示：

```python
import threading, time

def eat1(name):
    noodle_lock.acquire()
    time.sleep(3)
    print("%s获取面条"%name)
    fork_lock.acquire()
    print("%s获取叉子" % name)
    print("%s吃面" % name)
    fork_lock.release()
    noodle_lock.release()

def eat2(name):
    fork_lock.acquire()
    time.sleep(5)
    print("%s获取叉子"%name)
    noodle_lock.acquire()
    print("%s获取面条" % name)
    print("%s吃面" % name)
    noodle_lock.release()
    fork_lock.release()

if __name__ == '__main__':
    noodle_lock = threading.Lock()
    fork_lock = threading.Lock()

    threading.Thread(target=eat1, args=('zs',)).start()
    threading.Thread(target=eat2, args=('ls',)).start()
```

解决死锁问题：

```python
import threading, time

def eat1(name):
    noodle_lock.acquire()
    time.sleep(3)
    print("%s获取面条"%name)
    fork_lock.acquire()
    print("%s获取叉子" % name)
    print("%s吃面" % name)
    fork_lock.release()
    noodle_lock.release()

def eat2(name):
    fork_lock.acquire()
    time.sleep(5)
    print("%s获取叉子"%name)
    noodle_lock.acquire()
    print("%s获取面条" % name)
    print("%s吃面" % name)
    noodle_lock.release()
    fork_lock.release()

if __name__ == '__main__':
    noodle_lock = fork_lock = threading.RLock()
    threading.Thread(target=eat1, args=('zs',)).start()
    threading.Thread(target=eat2, args=('ls',)).start()
```

递归锁就是用来解决死锁问题的，注意的是：

- 在只有一个线程时，递归锁不起作用
- 对多个线程，如果一个线程拿到锁了（acquire），其它的就拿不到了

　　RLock内部维护着一个Lock和一个counter变量，counter记录了acquire的次数，从而使得资源可以被多次acquire。直到一个线程所有的acquire都被release，其他的线程才能获得资源。

### （三）信号量

同步锁允许在某一时刻一个线程来操作资源，但是信号量在某一时刻允许一定数量的线程操作资源。

信号量同步是基于内部计数器，每调用一次acquire()，计数器减1；每调用一次release()，计数器加1；当计数器为0时，acquire()调用被阻塞，直到有线程调用release()。

值得注意的是信号量也是锁，只是在内部加了一个计算器。

在火车站内需要对顾客进行检查，假设每次只能检查4个人，然后检查完毕的人再换下个顾客来检查，这里每次检查4个人就是信号量可以并发处理4个线程。

```python
import threading
import time


def check_person(i, sem):
    sem.acquire()
    print("检查{}".format(i), time.ctime())
    time.sleep(1)
    sem.release()


if __name__ == '__main__':
    sem = threading.Semaphore(4)  # 同时四个人进行检查

    for i in range(50):
        t = threading.Thread(target=check_person, args=(i, sem))
        t.start()

```

### （四）threading.Event

#### 1、Event事件概述

- 这是线程之间通信的最简单机制之一：一个线程发出事件信号，其他线程等待事件。
- 事件对象管理一个内部标志，该标志可以通过方法设置为true，并通过 `set()`方法设置为false `clear()` 。该`wait()`方法将阻塞直到标志为真。
- 所以事件对象的机制就是：全局定义了一个Flag，如果Flag值为 False，当程序执行event.wait()方法时就会阻塞，如果Flag值为True时，程序执行event.wait()方法时不会阻塞继续执行。

#### 2、常用属性、方法

- `is_set`（）

当且仅当内部标志Flag为True时，才返回True。

- `set`（）

将内部标志Flag设置为True。唤醒所有等待变为真的线程。`wait()`一旦标志为True的线程将根本不会阻塞。

- `clear`（）

将内部标志Flag重置为False。随后，线程调用 `wait()`将阻塞，直到`set()`被调用以再次将内部标志设置为True为止。

- `wait`（timeout = None ）

阻塞直到内部标志Flag为真。如果内部标志在输入时为True，立即返回。否则，阻塞直到另一个线程调用`set()`将该标志设置为True，或者直到发生可选的超时为止。如果存在timeout参数而不是timeout参数`None`，则它应该是一个浮点数，以秒为单位（或几分之一）指定操作的超时时间。当且仅当内部标志在等待调用之前或等待开始之后设置为True时，此方法才返回True，因此它将始终返回`True，`除非给出了超时且操作超时。

```python
import threading
import time


def light(e):
    """更改红绿灯"""
    while True:
        if e.is_set():  # 是绿灯
            e.clear()
            print("红灯亮了！")
        else:
            e.set()  # 更改绿灯 flag = True
            print("绿灯亮了！")
            time.sleep(0.2)


def cars(e, i):
    """具体的车, 根据event的状态来进行停车或者行走"""
    if e.is_set:
        print("%s车过马路了" % i)
    else:
        print("%s车等在十字路口" % i)
        e.wait()  # 阻塞, 直到 flag=True


if __name__ == '__main__':
    e = threading.Event()  # 默认为False,红灯

    t = threading.Thread(target=light, args=(e,))
    t.start()  # 启动一个红绿灯的线程

    car_list = []
    for i in range(10):
        car = threading.Thread(target=cars, args=(e, i))
        car_list.append(car)
        car.start()

    [car.join() for car in car_list]
    t.join()

```

## 五、线程通信

### （一）queue模块

#### 1、队列使用的必要性

当必须在多个线程之间安全地交换信息时，它就显得尤为重要了，因为内置了很多锁，保证了数据的安全性。

#### 2、queue模块中的类

- queue.Queue(maxsize = 0)

　　FIFO（先进先出）队列的构造函数。 maxsize是一个整数，用于设置可以放入队列中的项目数的上限。一旦达到此大小，插入将被阻塞，直到消耗队列项目为止。如果 maxsize小于或等于零，则队列大小为无限。

- queue.LifoQueue(maxsize = 0)

　　LIFO（后进先出）队列的构造函数。 maxsize是一个整数，用于设置可以放入队列中的项目数的上限。一旦达到此大小，插入将被阻塞，直到消耗队列项目为止。如果 maxsize小于或等于零，则队列大小为无限。

- queue.PriorityQueue(maxsize = 0)

　　优先级队列的构造函数。 maxsize是一个整数，用于设置可以放入队列中的项目数的上限。一旦达到此大小，插入将被阻塞，直到消耗队列项目为止。如果 maxsize小于或等于零，则队列大小为无限。
最低值的条目将首先被检索（最低值的条目是由返回的条目sorted(list(entries))[0]）。条目的典型模式是形式为元组(priority_number, data)。

- 异常queue.Empty

在空对象上调用非阻塞`get()`（或 `get_nowait()`）时引发异常Queue。

- 异常queue.Full

在已满的队列对象上调用非阻塞put()（或 put_nowait()）时引发异常Queue。

　　该模块实现了三种类型的队列，它们的区别仅在于检索条目的顺序不同。在FIFO 队列中，首先检索到添加的第一个任务。在 LIFO队列中，最近添加的条目是第一个检索到的条目（操作类似于堆栈）。使用优先级队列，条目将保持排序（使用`heapq`模块），并且最先检索值最低的条目。``

　　在内部，该模块使用锁来临时阻止竞争线程。

#### 3、队列对象

队列对象（Queue，LifoQueue或PriorityQueue）提供的公共方法：

- Queue.qsize()

返回队列的大小。注意，qsize()> 0不能保证后续的get()不会阻塞，qsize()<maxsize也不能保证put（）不会阻塞。

- Queue.empty()

如果返回True，队列为空。注意，如果返回True，不能保证后续put()的调用都不会阻塞。同样，如果empty()返回False，也不能保证get()的后续调用不会阻塞。

- Queue.full()

如果队列已满，返回True，否则返回False。注意，如果full()返回True，不能保证get()的后续调用不会阻塞。同样，如果full()返回False，也不能保证后续put()的调用都不会阻塞。

- Queue.put（item，block = True，timeout = None ）

　　将item放入队列。如果可选的args、block为True且timeout为 None（默认），则在必要时阻塞，直到有可用插槽可用。如果 超时为正数，则它最多会阻塞超时的时间，Full如果在该时间内没有空闲插槽可用，则会引发异常。否则（block为False），如果在该时间内没有空闲插槽可用，则会引发异常。如果有空闲插槽立即可用，则将item放在队列中。否则引发Full异常（在这种情况下将忽略超时）。

- Queue.put_nowait（item）

等同于put(item, False)

- Queue.get（block = True，timeout = None ）

　　从队列中删除并返回一个item。如果可选的args block为true，并且 timeout为None默认值，则在必要时阻塞，直到有可用的item为止。如果超时为正数，则它最多会阻塞超时的时间，Empty如果在该时间内没有可用的item，则会引发异常。否则（block为false），如果有立即可用的item，则返回一个item，否则引发Empty异常（在这种情况下，超时将被忽略）。

- Queue.get_nowait()

等同于get(False)。

- Queue.task_done()

在完成一项工作之后，Queue.task_done() 函数向任务已经完成的队列发送一个信号

- Queue.join()

阻塞直到队列中的所有item都已获得并处理。实际上意味着等到队列为空，再执行别的操作。
每当将item添加到队列时，未完成任务的数量就会增加。每当使用者线程调用task_done()以指示已检索到该item并且该item的所有工作完成时，该计数就会减少。当未完成的任务数降至零时，join()取消阻止。

### （二）使用

#### 1、先进先出队列

```python
import queue
import threading
import time


def do_work(item):
    print("%s任务已经完成" % item)
    time.sleep(0.2)


def worker():
    """每一个线程"""
    while True:
        item = q.get()
        if item is None:
            break
        # 处理任务的具体逻辑
        do_work(item)
        q.task_done()  # 任务完成后向队列发送一个通知信号


if __name__ == '__main__':
    q = queue.Queue()  # 实例化一个 先进先出 队列
    t_list = []
    num_worker_threads = 5

    # 将10个任务放入到队列中
    for item in range(10):
        q.put(item)

    # 5个工作线程处理任务
    for _ in range(num_worker_threads):
        t = threading.Thread(target=worker)
        t.start()
        t_list.append(t)

    # 等待队列中所有任务全部取出并且进行处理
    q.join()

    # 等待所有的工作线程结束
    for _ in range(num_worker_threads):
        q.put(None)

    [t.join() for t in t_list]

```

#### 2、其它队列

```python
import queue

#LifoQueue后进先出
q = queue.LifoQueue()

q.put(1)
q.put(2)
print(q.get()) #输出为2，后进先出，类似栈

# PriorityQueue 优先队列，put参数传入为一个元组 (优先级，要传入得值)
# 数字越小，代表优先级越高。当优先级一样的时候，根据传入的值的 ASCII 码值的顺序，进行排列
q = queue.PriorityQueue()
q.put((11,'zhangsan'))
q.put((2,'lisi'))
q.put((6,'wangwu'))
print(q.get()) #输出(2, 'lisi')
```

## 六、实战





















